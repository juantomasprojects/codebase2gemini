{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juantomasprojects/codebase2gemini/blob/main/analyze_codebase_with_gemini_1_5_pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bCIMTPB1WoTq"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPmcMNgZpo9V"
      },
      "source": [
        "# Analyze a codebase with the Vertex AI Gemini 1.5 Pro\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/code/analyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fcode%2Fanalyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/code/analyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/code/analyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EExYZvij2ve"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Eric Dong](https://github.com/gericdong), [Aakash Gouda](https://github.com/aksstar)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yVV6txOmNMn"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Gemini 1.5 Pro introduces a breakthrough long context window of up to 1 million tokens that can help seamlessly analyze, classify and summarize large amounts of content within a given prompt. With its long-context reasoning, Gemini 1.5 Pro can analyze an entire codebase for deeper insights.\n",
        "\n",
        "In this tutorial, you learn how to analyze an entire codebase with Gemini 1.5 Pro and prompt the model to:\n",
        "\n",
        "- **Analyze**: Summarize codebases effortlessly.\n",
        "- **Guide**: Generate clear developer getting-started documentation.\n",
        "- **Debug**: Uncover critical bugs and provide fixes.\n",
        "- **Enhance**: Implement new features and improve reliability and security.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdMGtr18rFdL"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --user --quiet google-cloud-aiplatform \\\n",
        "                                        gitpython \\\n",
        "                                        magika"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"abadia-1\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbozY-XKee95"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NSCFmvOWBas9"
      },
      "outputs": [],
      "source": [
        "import IPython.display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from vertexai.generative_models import (\n",
        "    FunctionDeclaration,\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Tool,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNoOTMp2fe33"
      },
      "source": [
        "## Cloning a codebase\n",
        "\n",
        "You will use repo [Online Boutique](https://github.com/GoogleCloudPlatform/microservices-demo) as an example in this notebook. Online Boutique is a cloud-first microservices demo application. The application is a web-based e-commerce app where users can browse items, add them to the cart, and purchase them. This application consists of 11 microservices across multiple languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlDOs49qgStM"
      },
      "outputs": [],
      "source": [
        "# The GitHub repository URL\n",
        "repo_url = \"https://github.com/LaAbadIAdelCrimen/abadia-gym\"  # @param {type:\"string\"}\n",
        "\n",
        "# The location to clone the repo\n",
        "repo_dir = \"./repo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAm1ly9pfIEX"
      },
      "source": [
        "#### Define helper functions for processing GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stNia6UaHau2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import git\n",
        "import magika\n",
        "\n",
        "m = magika.Magika()\n",
        "\n",
        "\n",
        "def clone_repo(repo_url, repo_dir):\n",
        "    \"\"\"Clone a GitHub repository.\"\"\"\n",
        "\n",
        "    if os.path.exists(repo_dir):\n",
        "        shutil.rmtree(repo_dir)\n",
        "    os.makedirs(repo_dir)\n",
        "    git.Repo.clone_from(repo_url, repo_dir)\n",
        "\n",
        "\n",
        "def extract_code(repo_dir):\n",
        "    \"\"\"Create an index, extract content of code/text files.\"\"\"\n",
        "\n",
        "    code_index = []\n",
        "    code_text = \"\"\n",
        "    for root, _, files in os.walk(repo_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            relative_path = os.path.relpath(file_path, repo_dir)\n",
        "            code_index.append(relative_path)\n",
        "\n",
        "            file_type = m.identify_path(Path(file_path))\n",
        "            if file_type.output.group in (\"text\", \"code\"):\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as f:\n",
        "                        code_text += f\"----- File: {relative_path} -----\\n\"\n",
        "                        code_text += f.read()\n",
        "                        code_text += \"\\n-------------------------\\n\"\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    return code_index, code_text\n",
        "\n",
        "\n",
        "def get_github_issue(owner: str, repo: str, issue_number: str) -> str:\n",
        "    headers = {\n",
        "        \"Accept\": \"application/vnd.github+json\",\n",
        "        \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    }  # Set headers for GitHub API\n",
        "\n",
        "    # Construct API URL\n",
        "    url = f\"https://api.github.com/repos/{owner}/{repo}/issues/{issue_number}\"\n",
        "\n",
        "    try:\n",
        "        response_git = requests.get(url, headers=headers)\n",
        "        response_git.raise_for_status()  # Check for HTTP errors\n",
        "    except requests.exceptions.RequestException as error:\n",
        "        print(f\"Error fetching issue: {error}\")  # Handle potential errors\n",
        "\n",
        "    issue_data = response_git.json()\n",
        "    if issue_data:\n",
        "        return issue_data[\"body\"]\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1UyVuQLuTKE"
      },
      "source": [
        "#### Create an index and extract content of a codebase\n",
        "\n",
        "Clone the repo and create an index and extract content of code/text files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rqaYzmNQuTKQ"
      },
      "outputs": [],
      "source": [
        "clone_repo(repo_url, repo_dir)\n",
        "\n",
        "code_index, code_text = extract_code(repo_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a local file with the content of the code_text variable\n",
        "\n",
        "with open(\"codebase.txt\", \"w\") as f:\n",
        "  f.write(code_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "ge-TzS3SKSwH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiVQB5SKekS0"
      },
      "source": [
        "## Analyzing the codebase with Gemini 1.5 Pro\n",
        "\n",
        "With its long-context reasoning, Gemini 1.5 Pro can process the codebase and answer questions about the codebase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1nfXrqRxVX"
      },
      "source": [
        "#### Load the Gemini 1.5 Pro model\n",
        "\n",
        "Learn more about the [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vB9gY3WruzK9"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-1.5-pro-001\"  # @param {type:\"string\"}\n",
        "\n",
        "model = GenerativeModel(\n",
        "    MODEL_ID,\n",
        "    system_instruction=[\n",
        "        \"You are a coding expert.\",\n",
        "        \"Your mission is to answer all code related questions with given context and instructions.\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yedKsUEEvNyb"
      },
      "source": [
        "#### Define a helper function to generate a prompt to a code related question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1DGzMhjCvCpj"
      },
      "outputs": [],
      "source": [
        "def get_code_prompt(question):\n",
        "    \"\"\"Generates a prompt to a code related question.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Questions: {question}\n",
        "\n",
        "    Context:\n",
        "    - The entire codebase is provided below.\n",
        "    - Here is an index of all of the files in the codebase:\n",
        "      \\n\\n{code_index}\\n\\n.\n",
        "    - Then each of the files is concatenated together. You will find all of the code you need:\n",
        "      \\n\\n{code_text}\\n\\n\n",
        "\n",
        "    Answer:\n",
        "  \"\"\"\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3OtaszvJt9L"
      },
      "source": [
        "### 1. Summarizing the codebase\n",
        "\n",
        "\n",
        "Generate a summary of the codebase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uMexx1Qtf1ML",
        "outputId": "02675fc5-b4e1-4f69-841f-d0e360d4dbef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:\n",
            "This codebase is an OpenAI gym environment for simulating the classic Spanish adventure game \"La Abadía del Crimen\" (\"The Abbey of Crime\"). It also includes several AI agents that interact with this environment, ranging from simple random agents to more sophisticated deep Q-learning agents.\n",
            "\n",
            "Here's a summary of the codebase:\n",
            "\n",
            "**1.  gym_abadia**: This is the core of the project, implementing the OpenAI gym environment for \"The Abbey of Crime.\" It defines the game's state space (e.g., positions of characters, game variables), action space (possible actions the agent can take), reward function (how the agent is rewarded for its actions), and game logic. \n",
            "\n",
            "**2.  Agents**: The codebase includes several Python scripts implementing different agents for interacting with the \"Abadia\" environment. \n",
            "    * **agentv1.py**: Implements a \"Do Nothing\" agent, essentially a baseline that takes random actions.\n",
            "    * **agentv2_qlearning.py & agentv3_qlearning.py**: Implement simple Q-learning agents, which learn by building a table of state-action values.\n",
            "    * **agentv4_dqn.py & agentv5_dqn.py**: Introduce Deep Q-learning agents, using neural networks to approximate the Q-function.\n",
            "    * **agentv6_ngdqn.py**: Implements a \"Next Generation\" Deep Q-learning agent, featuring a more complex architecture and potentially incorporating techniques like Convolutional Neural Networks (CNNs) and mixed models.\n",
            "\n",
            "**3.  Training and Testing**: The codebase includes scripts for training and testing the agents:\n",
            "    * **training_VDQN.py & training_NGDQN.py**: Train the value and \"Next Generation\" Deep Q-learning agents using pre-collected game data.\n",
            "    * **pre_training_VDQN.py & pre_training_NGDQN.py**: Prepare training data by extracting feature vectors from recorded game actions.\n",
            "    * **test_VDQN.py & test_NGDQN.py**: Test the trained agents by evaluating their performance in the \"Abadia\" environment.\n",
            "    * **Various shell scripts (loopagentv*.sh, loop_testv*.sh)**: Automate training and testing procedures, often with options for checkpointing and resuming.\n",
            "\n",
            "**Top 3 Things You Can Learn**:\n",
            "\n",
            "1. **OpenAI Gym Environments**:  The `gym_abadia` package demonstrates how to create a custom OpenAI gym environment for a specific game. You can learn about defining observation and action spaces, implementing game logic, and calculating rewards.\n",
            "2. **Reinforcement Learning Algorithms**:  The agent scripts showcase a progression of RL algorithms, from basic Q-learning to Deep Q-learning with increasingly complex neural network architectures. You can learn how these algorithms work and how to implement them using libraries like Keras.\n",
            "3. **Training and Evaluating RL Agents**:  The training and testing scripts illustrate techniques for training RL agents using replay memory, target networks, and experience replay. You can also learn about evaluating agent performance and checkpointing models for later use.\n",
            "\n",
            "\n",
            "Usage metadata:\n",
            "{'prompt_token_count': 90386, 'candidates_token_count': 660, 'total_token_count': 91046}\n",
            "\n",
            "Finish reason:\n",
            "1\n",
            "\n",
            "Safety settings:\n",
            "[category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.07892588526010513\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.06383160501718521\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.11027936637401581\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.10466019809246063\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.11596072465181351\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.03327394276857376\n",
            ", category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.04885777831077576\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.06052938848733902\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  Give me a summary of this codebase, and tell me the top 3 things that I can learn from it.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "# Generate text using non-streaming method\n",
        "response = model.generate_content(contents)\n",
        "\n",
        "# Print generated text and usage metadata\n",
        "print(f\"\\nAnswer:\\n{response.text}\")\n",
        "print(f'\\nUsage metadata:\\n{response.to_dict().get(\"usage_metadata\")}')\n",
        "print(f\"\\nFinish reason:\\n{response.candidates[0].finish_reason}\")\n",
        "print(f\"\\nSafety settings:\\n{response.candidates[0].safety_ratings}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCshJHPCYoxI"
      },
      "source": [
        "### 2. Creating a developer getting started guide\n",
        "\n",
        "Generate a getting started guide for developers. This sample uses the streaming option to generate the content."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a local file with the content of the prompt variable\n",
        "\n",
        "with open('prompt.txt', 'w') as f:\n",
        "  f.write(prompt)\n"
      ],
      "metadata": {
        "id": "g-u3hSNVKtO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e6Kns7vCYm1P",
        "outputId": "1d161498-2251-4a3e-b584-74e1be23531e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "python\nimport gym\nimport gym_abadia\n\nenv = gym.make"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "('abadia-v0')\n```\n\nTo onboard new developers to this"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " codebase, follow these steps:\n\n**1. Setup**\n\n* **Clone the Repository:** `git clone https://github.com/LaAbad"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "IAdelCrimen/abadia-gym.git`\n* **Install Python 3:** Ensure Python 3 is installed on your system.\n*"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " **Virtual Environment (Recommended):** Create a virtual environment to isolate dependencies:\n    * `apt install virtualenv python3-pip`\n    * `virtualenv -p python3 python3`\n    * `source ./python"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "3/bin/activate`\n* **Install Dependencies:** Install the required libraries listed in `requirements.txt`:\n    * `pip3 install -r requirements.txt`\n* **Download Models:** Create directories for snapshots and models"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", then download the latest models:\n    * `mkdir -p snapshots models`\n    * `cd models/`\n    * `wget https://storage.googleapis.com/abadia-data/models/last_model_v6.model`\n    * `wget https://storage.googleapis"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".com/abadia-data/models/last_value_v1.model`\n    * `cd ..`\n\n**2. Understanding the Project**\n\n* **Project Overview:** The project simulates the environment of the game \"The Abbey of Crime\" (AbadIA).  It provides an Open"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "AI Gym environment (`gym_abadia`) and AI agents that can interact with the game.\n* **Game Engine:** The game engine is a separate project, VigasocoSDL-AI. You can find instructions on setting it up in the `README.md` file.\n* **Gym Environment:**  "
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "`gym_abadia` creates a Gym environment for AbadIA, enabling you to train AI agents to play the game.\n* **AI Agents:** Several AI agents are included, ranging in complexity from random actions (`agentv1.py`) to deep reinforcement learning models (`agentv6_ngdqn."
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "py`).\n\n**3. Running the Agents**\n\n* **Agent v6 (NGDQN):**\n    * **Training:** `python3 agentv6_ngdqn.py --learning=true --episodes=5 --steps=2000`\n    * **Playing:** `python"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "3 agentv6_ngdqn.py --learning=false --episodes=5 --steps=2000 --initmodel=models/last_model_v6.model`\n    * **Looping:** `./loopagentv6.sh`\n* **Other Agents:** Refer"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " to the `README.md` file for instructions on running other agents.\n\n**4. Code Structure**\n\n* **`gym_abadia`:** Contains the Gym environment code.\n* **`AbadIA`:** Houses different AI agent implementations (DQN, NGDQN, VDQN)."
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n* **`tools`:**  Scripts for managing datasets, checkpoints, and training processes.\n* **`k8s`:** Kubernetes configurations for running the project in a containerized environment.\n\n**5. Contributing**\n\n* **Issues:**  Report bugs or suggest improvements by opening issues on the GitHub repository"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".\n* **Pull Requests:** Contribute code changes through pull requests. Ensure your code follows the existing coding style and includes tests.\n\n**6. Resources**\n\n* **GitHub Repository:**  https://github.com/LaAbadIAdelCrimen/abadia-gym\n* **OpenAI Gym Documentation"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ":**  https://gym.openai.com/docs/\n\n**7. Additional Notes**\n\n* The `README.md` file provides a starting point for understanding the project.\n* Explore the code and experiment with different agents and settings.\n* The `tools` directory contains scripts that can be helpful"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " for data management and training.\n* Use the Kubernetes configurations in the `k8s` directory for deploying the project.\n"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  Provide a getting started guide to onboard new developers to the codebase.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXurINu-jelb"
      },
      "source": [
        "### 3. Finding bugs\n",
        "\n",
        "Find the top 3 most severe issues in the codebase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fy3AWPRgNhu_",
        "outputId": "7ebd646d-a606-4099-fa5a-bce0c8d4d507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Let"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "'s break down the top 3 issues within this codebase, focusing on"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " maintainability, scalability, and best practices.\n\n**1. Tight Coupling and"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Lack of Modular Design**\n\n   * **Problem:** Many components (especially the agents and the environment) are intertwined. Functions within `AbadiaEnv2`"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " directly manipulate agent-specific variables (e.g., `self.valMovs`, `self.wallMovs`, `self.perMovs`)."
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " This tight coupling makes it difficult to: \n      * **Change Agents:**  Swapping out or upgrading an agent would likely require substantial modification of the `AbadiaEnv2` class.\n      * **Test Components:**  Is"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "olating individual units for testing is challenging.\n      * **Reuse Code:** Parts of the environment logic could potentially be useful in other projects, but its strong dependence on specific agents makes reuse difficult.\n   * **Solution:** \n"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "      * **Interface/Abstract Classes:** Define clear interfaces or abstract classes for both agents and the environment. This enforces structure and allows agents to interact with the environment in a standardized way. \n      * **Separate Concerns:**  \n          * Move agent-specific logic (like valid move calculations) entirely into the"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " agent classes. The environment should only provide generic information about the game state. \n          *  Consider using a state object or dictionary to encapsulate the game state information passed between the environment and the agent. \n\n**2. Hardcoded Values and \"Magic Numbers\"**\n\n   * **Problem:** The code"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " relies heavily on hardcoded values (e.g., `final[ii] = -99`,  magic numbers like `32` for batch size, or the specific format of the checkpoint filenames).\n      * **Readability:** It becomes harder for someone unfamiliar with the code to understand the purpose of these"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " values.\n      * **Maintainability:** If any of these values need to be changed, they have to be manually tracked down and modified in multiple places, increasing the risk of errors. \n   * **Solution:**\n      * **Constants:** Use named constants to store important values. This improves readability and makes"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " it easier to update values centrally. For example: \n         ```python\n         BATCH_SIZE = 32\n         INVALID_MOVE_PENALTY = -99 \n         CHECKPOINT_FILENAME_FORMAT = \"abadia_checkpoint_{}_{}_{}_{}_{}_{}.checkpoint\"\n         ```\n"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "      * **Configuration Files:** Consider moving configuration parameters (like server address, model names, learning rates) to a separate configuration file (JSON, YAML, etc.). This makes it easy to modify settings without altering the core code.\n\n**3. Inconsistent Logging and Debugging**\n\n   * **Problem:** The code"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " mixes `print` statements with `logging` calls.\n      * **Production vs. Development:**  Print statements can clutter output in a production environment.\n      * **Log Management:** A dedicated logging framework provides features for controlling log levels, output formats, and routing logs to different destinations (files, network, etc"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".).\n   * **Solution:**\n     * **Consistent Logging:** Standardize on the `logging` module. Set appropriate log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL). This makes it easier to filter and manage logs based on their severity.\n     * **Advanced Logging:** Explore more advanced logging configurations"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " and tools (e.g., log rotation, centralized logging servers) to handle larger volumes of logs.\n\n**Beyond the Top 3**\n\n* **State Representation:** The way the game state is converted to a vector (`state2vector` function) could be improved for clarity and efficiency. Consider using data structures"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " that more naturally align with the game's elements (perhaps a dictionary or a custom object). \n* **Multithreading:** The use of threads in `agentv6_ngdqn.py` for uploading models is a good start, but more systematic multithreading or multiprocessing could potentially be applied to speed up"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " training or other compute-intensive parts of the code.\n* **Code Organization:** You might benefit from a more structured project directory layout. Consider organizing code into logical modules and packages, separating core functionality from tests, scripts, and configuration.\n\nBy addressing these issues, you'll significantly enhance the codebase's"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " quality, making it easier to understand, maintain, and extend in the future. \n"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  Find the top 3 most severe issues in the codebase.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCilrR6FjmfB"
      },
      "source": [
        "### 4. Fixing bug\n",
        "\n",
        "Find the most severe issue in the codebase that can be fixed and provide a code fix for it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dwjDh0xGKE2r",
        "outputId": "6ffcad07-b8b2-4104-b53c-26ce7c7f4aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "diff\n--- a/AbadIA/VDQN.py\n+++ b"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "/AbadIA/VDQN.py\n@@ -1579"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ",7 +1579,7 @@\n             actionType = \"E\"\n             self.env.calculated_predictions = []\n             self"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".env.final_predictions = []\n-        else:\n+        elif self.env.playing is True:\n             predictions = self.model"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".predict(vector.reshape(1,1,71)).reshape(9)\n             logging.info(predictions)\n             self.env.predictions = predictions\n@@ -1612,6 +161"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "2,9 @@\n         self.env.action_predictions = int(action)\n         self.env.action_type = actionType\n \n+        # in playing mode we only want to return a prediction\n+"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        if (self.env.playing is True):\n+            action =  np.argmax(predictions)\n         return action\n \n     def remember(self, state, action, reward, new_state, done):\n\n```"
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  Find the most severe bug in the codebase that you can provide a code fix for.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w2pCULT_xKE"
      },
      "source": [
        "### 5. Implementing a feature request using Function Calling\n",
        "\n",
        "Generate code to implement a feature request.\n",
        "\n",
        "Get feature request text from GitHub Issue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mMjOy0gJ1_xx",
        "outputId": "ef2d8f72-1609-42cd-d86c-a7edda3fdce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Feature Request:\n### Describe request or inquiry \r\nhelm chart frontend-external support config service type nodeport, like this\r\n```\r\nhelm install xxx --set frontend.service.type=NodePort\r\n```\r\n\r\n### What purpose/environment will this feature serve? \r\n\r\nThis feature enables quick access to the front-end web interface of microservices without the need for additional configuration work.\r\n\r\nI hope to quickly access the web interface after deploying this microservice in the local environment, without the need for additional loadbalancer or ingress configuration, just nodeport is enouth.\r\n\r\nBut now that the deployment is complete, I must manually edit the service and modify the nodeport. If Helm provides parameters to set the nodeport, I don't need to。\r\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Function declaration with detailed docstring\n",
        "extract_details_from_url_func = FunctionDeclaration(\n",
        "    name=\"extract_details_from_url\",\n",
        "    description=\"Extracts owner, repository name, and issue number details from a GitHub issue URL\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"owner\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The owner of the GitHub repository.\",\n",
        "            },\n",
        "            \"repo\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the GitHub repository.\",\n",
        "            },\n",
        "            \"issue_number\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The issue number to fetch the body of.\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "# Tool definition\n",
        "extraction_tool = Tool(function_declarations=[extract_details_from_url_func])\n",
        "\n",
        "FEATURE_REQUEST_URL = (\n",
        "    \"https://github.com/GoogleCloudPlatform/microservices-demo/issues/2205\"\n",
        ")\n",
        "\n",
        "# Prompt content\n",
        "prompt_content = f\"What is the feature request of the following {FEATURE_REQUEST_URL}\"\n",
        "\n",
        "# Model generation with tool usage\n",
        "response = model.generate_content(\n",
        "    [prompt_content],\n",
        "    generation_config=GenerationConfig(temperature=0),\n",
        "    tools=[extraction_tool],\n",
        ")\n",
        "# Extract parameters from model response\n",
        "function_call = response.candidates[0].function_calls[0]\n",
        "\n",
        "# Fetch issue details from GitHub API if function call matches\n",
        "if function_call.name == \"extract_details_from_url\":\n",
        "    issue_body = get_github_issue(\n",
        "        function_call.args[\"owner\"],\n",
        "        function_call.args[\"repo\"],\n",
        "        function_call.args[\"issue_number\"],\n",
        "    )\n",
        "\n",
        "IPython.display.Markdown(f\"Feature Request:\\n{issue_body}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hm7NO2FgSWF"
      },
      "source": [
        "Use the GitHub Issue text to implement the feature request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8HElfnYEgSWF",
        "outputId": "2d5c86b5-04a6-4a98-db2e-6583ca99b6f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```diff\n--- a/kubernetes/abadia-v6/charts/abadia-agent-ng/templates/service.yaml\n+++ b/kubernetes/abadia-agent-ng/templates/service.yaml\n@@ -7,4 +7,4 @@\n   ports:\n   - protocol: TCP\n     port: 80\n-    targetPort: 4477\n+    targetPort: {{ .Values.service.targetPort }}\n   type: {{ .Values.service.type }}\n\n```"
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Combine feature request with URL and get code prompt\n",
        "question = (\n",
        "    \"Implement the following feature request\" + FEATURE_REQUEST_URL + \"\\n\" + issue_body\n",
        ")\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "\n",
        "# Generate code response\n",
        "response = model.generate_content([prompt])\n",
        "IPython.display.Markdown(response.text)  # Display in Markdown format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOk_Qe35b_cJ"
      },
      "source": [
        "### 6. Creating a troubleshooting guide\n",
        "\n",
        "Create a troubleshooting guide to help resolve common issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DKn85LS-v0iw",
        "outputId": "d17b594b-31fd-4983-bf7b-a3227168765f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "python\nimport random\nimport numpy as np\nimport logging\nimport json\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "import gzip\nfrom math import hypot\nfrom math import atan2\nimport pickle"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nimport os\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "from collections import deque\n\n# TODO JT:\n# 1) Need a method to fill the memory with actions\n# 2) Need a method to"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " training / validating out the agent\n# 3) A method to get the history of the training/validating\n# 4) a method to convert from the json format to the input vector\n\nclass NGDQN:\n    "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "def __init__(self, env=None, modelName=None, initModelName=None, gsBucket=None):\n        self.env     = env\n        self.memory  = deque(maxlen=100"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "00)\n        # Exploring or playing\n\n        self.gamma = 0.85\n        self.epsilon = 1.0\n        self.epsilon_min = 0.01 # previously 0.01\n        self.epsilon_decay = 0.995"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n        self.learning_rate = 0.005\n        self.tau = .125\n        self.initModelName = None\n        self.modelName = None\n        self.valueModelName = None\n        self.gsBucket = None\n\n        logging.basicConfig(format"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "='%(asctime)s:%(levelname)s:%(message)s', datefmt='%d-%m-%y %H:%M:%S',\n                            level=logging.INFO)\n\n        self.logging = logging\n\n        # TODO JT: we need to implement this when goes to production\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        if env != None:\n            if env.initModelName != None:\n                self.initModelName = env.initModelName\n            if env.modelName != None:\n                self.ModelName = env.modelName\n\n        if modelName != None:\n            self.modelName = model"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Name\n\n        if initModelName != None:\n            self.initModelName = initModelName\n\n        self.model        = self.create_model()\n        self.target_model = self.create_model()\n\n        if (self.initModelName is not None):\n            fileName"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " = self.initModelName\n        else:\n            fileName = self.modelName\n\n        if self.env != None:\n            if (env.gsBucket != None):\n            # TODO JT: we need to implement this when goes to production\n                self.env.download_blob(fileName,"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " fileName)\n                self.logging.info(\"Downloading the model from Bucket: {} file: {}\".format(self.gsBucket, fileName))\n\n        if (not (env == None and modelName == None and initModelName == None)):\n            self.model        = self.load_model(fileName"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ")\n            self.target_model = self.load_model(fileName)\n\n    def create_model(self, input_dim=71, output_dim=9):\n        self.logging.info(\"Creating a new model v6\")\n        model   = Sequential()\n        #"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " TODO JT we need to increment the input vector dim\n        # for now the input_dim is 71 with chars, env + validmods\n\n        state_shape  = input_dim # self.env.observation_space.shape\n\n        # TODO JT we need to redesign the internal lawyers\n\n        "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "model.add(Dense(64, input_shape=(1,71), activation=\"relu\"))\n        model.add(Dense(128, activation=\"relu\"))\n        model.add(Dense(64, activation=\"relu\"))\n        model.add(Dense(32,"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " activation=\"relu\"))\n        model.add(Dense(output_dim))\n        model.compile(loss=\"mean_squared_error\",\n            optimizer=Adam(lr=self.learning_rate),\n            metrics=['accuracy'])\n        return model\n\n\n    def create_model2(self,"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " input_dim=71, output_dim=9):\n        self.logging.info(\"Creating a new model2 v6\")\n        model   = Sequential()\n        # TODO JT we need to increment the input vector dim\n        # for now the input_dim is 71 with chars"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", env + validmods\n\n        state_shape  = input_dim # self.env.observation_space.shape\n\n        # TODO JT we need to redesign the internal lawyers\n\n        model.add(Dense(64, input_shape=(1,71), activation=\"relu\"))\n        model"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".add(Dense(128, activation=\"relu\"))\n        model.add(Dense(64, activation=\"relu\"))\n        model.add(Dense(32, activation=\"relu\"))\n        model.add(Dense(output_dim))\n        model.compile(loss=\"mean"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "_squared_error\",\n            optimizer=Adam(lr=self.learning_rate),\n            metrics=['accuracy'])\n        return model\n\n    def load_model(self, name):\n        self.logging.info(\"Loading a local model from: ({})\".format(name))\n        #"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " we're calling the load_model method imported from keras\n        # and return the model loaded (h5 format)\n        return load_model(name)\n\n    def create_empty(self, name=\"models/model_v6\"):\n        model = self.create_model()\n        "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "self.save_model(name)\n        return model\n\n    def act(self, state):\n        self.epsilon *= self.epsilon_decay\n        self.epsilon = max(self.epsilon_min, self.epsilon)\n        if (self.env == None):\n            return act"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "_prediction(state)\n        else:\n            return self.act_env(state)\n\n    def act_prediction(self, vector):\n\n        # self.env.vector = vector\n\n        predictions = self.model.predict(vector)[0]\n        # self.env.predictions ="
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " predictions\n        # TODO JT: how to get the action_space\n        # final = np.zeros(self.env.action_space.n)\n\n        action = np.argmax(final)\n        # self.logging.info(\"vector:      {}              \".format(vector))\n        "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "self.logging.info(\"predictions: {}              \".format(predictions))\n        self.logging.info(\"final:       {}              \".format(final))\n        self.logging.info(\"Action:      {} Prediction: {}    \".format(action, final[action]))\n\n        return action\n\n    "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "def act_env(self, state):\n\n        # vector = self.env.stateVector()\n        vector = self.state2vector(state)\n        self.env.vector = vector\n\n        # exploratory mode\n        if (self.env.playing is False) and (np.random"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".random() < self.epsilon):\n            action = self.env.action_space.sample()\n            self.env.logging.info(\"e-greedy: {}  epsilon: {}<----               \".format(action, self.epsilon))\n            actionType = \"E\"\n            self"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".env.calculated_predictions = []\n            self.env.final_predictions = []\n        # explotation mode\n        else:\n            predictions = self.model.predict(vector.reshape(1,1,71)).reshape(9)\n            logging.info(predictions)\n            "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "self.env.predictions = predictions\n            final = np.zeros(self.env.action_space.n)\n\n            for ii in range(0,self.env.action_space.n):\n                if (self.env.valMovs[ii] >= 1):\n                    "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "final[ii] = predictions[ii]\n                else:\n                    final[ii] = -99 # predictions[ii]*0.9\n            # just testing a Mixed mode\n            # what will happen if we choose one of the best 3 actions random\n            # action = np.argmax"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(final)\n            idx = (-final).argsort()[:3]\n            action = idx[np.random.randint(0,2)]\n            # self.env.logging.info(\"vector:      {}              \".format(vector))\n            # self.env.logging.info(\""
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "predictions: {}              \".format(predictions))\n            # self.env.logging.info(\"final:       {}              \".format(final))\n            self.env.logging.info(\"Action:      {} Prediction: {}    \".format(action, final[action]))\n            for ii in range("
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "9):\n                self.env.logging.info(\"%3s %d:%d:%d -> %.8f %.8f\" % ( self.env.actions_list[ii],\n                                                                     self.env.valMovs[ii],\n                                                                     self.env.wallMo"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "vs[ii],\n                                                                     self.env.perMovs[ii],\n                                                                     predictions[ii],\n                                                                     final[ii]))\n            actionType = \"P\"\n\n            self.env.calculated_predictions = predictions.tolist()\n            self.env.final_"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "predictions = final.tolist()\n\n\n        self.env.vector_predictions = vector.tolist()\n        self.env.action_predictions = int(action)\n        self.env.action_type = actionType\n\n        return action\n\n    def remember(self, state, action, reward, new"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "_state, done):\n        self.memory.append([state, action, reward, new_state, done, 0])\n\n    def replay(self, verbose=0):\n        batch_size = 32\n        if len(self.memory) < batch_size:\n            "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "return\n\n        temp = self.memory\n        acu  = np.zeros(32)\n\n        # adding the future reward 32 rewards ahead to the vector information\n        for index in range(len(temp)-1, 0, -1):\n            acu[index % 32"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "] = temp[index][2]\n            temp[index][5]  = acu.sum()\n\n        samples = random.sample(temp, batch_size)\n        for sample in samples:\n            state, action, reward, new_state, done, future_reward = sample\n            "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# print(state)\n            target = self.target_model.predict((state.reshape(1,1,71))).reshape(9)\n            # print(target)\n            if done:\n                target[action] = future_reward\n            else:\n                # TODO JT:"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " MCTS? Q_future = max(self.target_model.predict(new_state)[0])\n                target[action] = future_reward # Q_future # reward + Q_future * self.gamma\n            history = self.model.fit(state.reshape(1, "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "1, 71), target.reshape(1, 1, 9), epochs=1, verbose=verbose)\n            # print(\"loss:\", history.history[\"loss\"], \"\\n\")\n\n    def replay_game(self, epochs=4, verbose=0):\n        batch_size"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " = 32\n        if len(self.memory) < batch_size:\n            logging.info(\"Not enough actions {}\".format(len(self.memory)))\n            return\n        else:\n            logging.info(\"We have {} samples for training\".format(len(self.memory)))"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n        temp = self.memory\n        acu  = np.zeros(32)\n\n        # adding the future reward 32 rewards ahead to the vector information\n        for index in range(len(temp)-1, 0, -1):\n            acu[index % 32]"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " = temp[index][2]\n            temp[index][5]  = acu.sum()\n\n        # TODO JT: we dont want to use the last 32 actions because we dont have the \"future\" score\n\n        states  = []\n        rewards = []\n        for sample in temp"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ":\n            state, action, reward, new_state, done, future_reward = sample\n            target = self.target_model.predict(state.reshape(1,1,71))\n            # TODO JT: we need to fix this for the case done is True\n            if done"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ":\n                target[0][0][action] = max(future_reward,target[0][0][action])\n            else:\n                target[0][0][action] = max(future_reward,target[0][0][action])\n\n            states.append(state)\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "            rewards.append(target)\n\n        X_data = np.array(states).reshape(len(states), 1, 71)\n        y_data = np.array(rewards).reshape(len(rewards), 1, 9)\n\n        size = int(len("
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "states)*77/100)\n        X_training = X_data[:size]\n        y_training = y_data[:size]\n\n        X_test = X_data[size:]\n        y_test = y_data[size:]\n\n        history = self.model"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".fit(X_training, y_training, validation_data=(X_test, y_test), \\\n                                epochs=epochs, batch_size=32, verbose=verbose)\n\n        print(\"loss:\", history.history[\"loss\"], \"\\n\")\n\n        score = self.model."
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "evaluate(X_test, y_test, verbose=verbose)\n        print(\"score:\", score)\n        return history, score\n\n    def target_train(self):\n        self.env.logging.info(\"training target ..\")\n        weights = self.model.get_weights()\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        target_weights = self.target_model.get_weights()\n        for i in range(len(target_weights)):\n            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n        self."
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "target_model.set_weights(target_weights)\n\n    def save_model(self, fn):\n        self.logging.info(\"Saving the model to the local file: {}\".format(fn))\n        self.model.save(fn)\n\n    def load_actions_from_a"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "_dir_and_save_to_vectors(self, dirName):\n        files = []\n        for entry in os.scandir(dirName):\n            if entry.is_file() and 'actions_' in entry.path:\n                self.load_actions_from_a_"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "file(entry.path)\n                tmpName = entry.path.replace(\"actions\", \"vectors\")\n                print(\"Processing: {} -> {}\".format(entry.path, tmpName))\n                self.save_actions_as_vectors(tmpName)\n                files.append(tmpName)"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n        return files\n\n    def load_vectors_from_a_dir(self, dirName):\n        self.memory = deque()\n        for entry in os.scandir(dirName):\n            if entry.is_file() and 'abadia_vectors_' in entry.path:"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n                logging.info(\"Loading: {} \".format(entry.path))\n                tmp = self.load_vectors_into_actions(entry.path)\n                for action in tmp:\n                    self.memory.append(action)\n                    # logging.info(\"vector: {}\".format(action"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "))\n                logging.info(\"Actions: {} total {}\".format(len(tmp), len(self.memory)))\n\n    def load_actions_from_a_file(self, fileName):\n        self.memory = deque(maxlen=10000)\n        if \".gz\" in"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " fileName:\n            json_data = gzip.open(fileName, 'rb')\n        else:\n            json_data = open(fileName)\n\n        # lines = json_data.readlines()\n        # if lines:\n        for line in json_data:\n            # if (len("
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "line) > 0 and line.startswith(\"[\")):\n            try:\n                state = json.loads(line)[0]\n                # print(\"{}\".format(state))\n\n                current_state = self.state2vector(state['action']['state'])\n                new_state = self."
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "state2vector(state['action']['state'])\n                action = state['action']['action']\n                reward = state['action']['reward']\n                self.remember(current_state, action, reward, new_state, False)\n            except:\n                print(\"json line read error\")\n\n\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "    def save_actions_as_vectors(self, filename):\n        with open(filename, 'wb') as f:\n            pickle.dump(self.memory, f)\n\n    def load_vectors_into_actions(self, filename):\n        with open(filename, 'rb')"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " as f:\n            return pickle.load(f)\n\n    def state2vector(self, state):\n\n        chars  = state['Personajes']\n        # print(chars)\n        vChars = np.zeros([4,7], np.float)\n        for ii in range(0"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", min(len(chars), 4)):\n            # print (ii, chars[ii]['nombre'], chars[ii]['posX'], chars[ii]['posY'])\n            vChars[ii][0] = float(chars[ii]['posX']/256)\n            vChars[ii]["
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "1] = float(chars[ii]['posY']/256)\n            vChars[ii][2] = float(chars[ii]['orientacion'] / 4)\n            vChars[ii][3] = float(chars[ii]['altura'] / 4)\n            if ("
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ii >= 1):\n                vChars[ii][4] = hypot(vChars[ii][0] - vChars[0][0], vChars[ii][1] - vChars[0][1])\n                vChars[ii][5] = atan2(vChars[ii"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "][0] - vChars[0][0], vChars[ii][1] - vChars[0][1]) / 3.14159\n            if (ii <= 1):\n                vChars[ii][6] = float(chars[ii]['objetos'] / "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "32)\n\n        # vEnv vector with the environment data\n        vEnv = np.zeros([10], np.float)\n        vEnv[0] = float(state['bonus']/100)\n        vEnv[1] = float(state['dia']/7)\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        vEnv[2] = float(state['momentoDia']/10)\n        vEnv[3] = float(state['numPantalla']/256)\n        vEnv[4] = float(state['numeroRomano']/10)\n        vEnv[5] = float"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(state['obsequium']/31)\n        vEnv[6] = float(state['planta']/3)\n        vEnv[7] = float(state['porcentaje']/100)\n        if len(state['Objetos']) >= 1:\n            vEnv[8"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "] = float(state['Objetos'][0]/32)\n\n        if 'jugada' in state:\n            vEnv[9] = float(state['jugada']/10000)\n\n        # print(vEnv)\n        vector = np.append(vChars.reshape"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "([1, 28]), vEnv)\n\n        # vAudio the last sounds\n        vAudio = np.zeros([12], np.float)\n        for ii in range(0, len(state['sonidos'])):\n            vAudio[ii] = float(state['son"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "idos'][ii]/64)\n\n        vector = np.append(vector, vAudio)\n\n        # vFrases the last frases\n        vFrases = np.zeros([12], np.float)\n        for ii in range(0, len(state['frases'])):\n            "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "vFrases[ii] = float(state['frases'][ii]/64)\n\n        vector = np.append(vector, vFrases)\n\n        # vValidm the validmovs\n        vValidm = np.zeros([9], np.float)\n        if 'valMo"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "vs' in state and state['valMovs'] != None:\n            for ii in range(len(state['valMovs'])):\n                vValidm[ii] = float(state['valMovs'][ii])\n\n        vector = np.append(vector, vValidm)\n\n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        # print(\"vector {}\".format(vector))\n        return vector.reshape(1,71)\n```\n\n## Troubleshooting guide\n\nThis guide will help you resolve common issues encountered when using this codebase.\n\n**1. Communication Errors**\n\n* **Symptom:** \"Communication Error: I cannot send the"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " CMDs\" or similar error messages in the logs.\n* **Possible Cause:** The game engine (VigasocoSDL) is not running or not accessible on the specified URL.\n* **Solution:**\n    - Ensure the game engine is running and accessible on the URL defined in the `env.url`"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " variable. \n    - Verify the server name, port, and URL are correctly configured in the agent's initialization (`init_env` function).\n    - Check for any firewalls or network issues that may be blocking communication between the agent and the game engine. \n\n**2. Downloading Errors**"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n* **Symptom:** \"Error downloading...\" or \"File ... not exist at bucket ...\".\n* **Possible Cause:** The file being downloaded from Google Cloud Storage (GCS) doesn't exist or there's an issue with GCS access.\n* **Solution:**\n    - Verify the `gsBucket"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "` name is correctly configured in the agent's initialization.\n    - Check if the file actually exists in the specified GCS bucket.\n    - Ensure your code has the necessary permissions to access GCS.\n\n**3. JSON Reading Errors**\n\n* **Symptom:** \"json line read error\" or issues"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " parsing JSON data.\n* **Possible Cause:** The JSON data being read from the action files is malformed or corrupted.\n* **Solution:**\n    - Inspect the action files for any invalid JSON syntax.\n    - If using gzip compressed files, ensure they are correctly decompressed before reading. \n    "
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- You can implement more robust error handling during JSON parsing, for example, by catching `json.decoder.JSONDecodeError` exceptions. \n\n**4. Not Enough Actions for Training**\n\n* **Symptom:** \"Not enough actions ...\" message during training. \n* **Possible Cause:** The agent's"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " memory doesn't have enough data (at least 32 samples) for the `replay_game` function. \n* **Solution:**\n    - Let the agent play more episodes and collect more data before attempting to train.\n    - Consider increasing the `maxlen` parameter of the `deque` used"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " for memory, if you want to store more actions.\n    - If loading actions from files, ensure the files are correctly read and loaded into memory. \n\n**5. General Tips**\n\n* **Logging:** Carefully review the log messages generated by the agents. These provide valuable information about the agent's actions"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", rewards, and potential errors encountered.\n* **Debugging:** Use a debugger to step through the code and understand its execution flow.\n* **Code Structure:**  Familiarise yourself with the code structure and how different components (agent, environment, training/playing modes) interact.\n* **Experimentation:** Try"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " different hyperparameter values (gamma, epsilon, learning rate) and model architectures to see their impact on the agent's performance. \n\nThis troubleshooting guide provides a starting point for resolving common issues. You may encounter other issues specific to your environment or use case. In such cases, carefully analyze error messages, log files"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", and the code's execution flow to pinpoint the source of the problem and devise a solution. \n"
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "    Provide a troubleshooting guide to help resolve common issues.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h23z0sTsj5pL"
      },
      "source": [
        "### 7. Making the app more reliable\n",
        "\n",
        "Recommend best practices to make the application more reliable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yOBSulTPLUAo",
        "outputId": "98854406-7752-4d7b-d710-5084d6b8fa7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " provided codebase is quite large and complex, making a comprehensive reliability analysis challenging without"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " a specific area of focus. However, based on the files you shared and the"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " link to best practices from R9y.dev, here's a general approach to improving the reliability of this application, focusing on common areas of improvement in"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " machine learning applications:\n\n**1. Input Validation and Handling**\n\n* **Robust data handling:**\n    * The code already includes some basic error handling for"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " JSON parsing in `AbadIA/NGDQN.py` and `AbadIA/VDQN.py`. \n    * Enhance this by implementing schema validation for all incoming JSON data (e.g., using `js"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "onschema` library) to ensure data integrity and prevent unexpected errors.\n    * Check for missing keys, incorrect data types, and out-of-range values.\n    * Consider implementing data cleaning and preprocessing steps to handle potential noise"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " or inconsistencies in the input data.\n\n* **Action validation:**\n    * The `checkValidMovs` function in `agentv5_dqn.py` and `agentv6_ngdqn.py` implements a form of action validation. \n    * Make it more comprehensive by considering"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " all possible invalid actions (out-of-bounds, illegal game actions) and handling them appropriately.\n    * Log invalid actions or raise exceptions with informative messages for debugging.\n\n**2. Model Training and Saving**\n\n* **Model checkpoints:** \n    * The codebase saves checkpoints at various points during training"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ". \n    * Implement a more systematic checkpointing strategy, saving models periodically based on epochs, time, or performance metrics.\n    * Use separate directories for different training runs or model versions.\n    * Consider implementing early stopping based on validation performance to prevent overfitting.\n\n* **Model versioning:**\n"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "    * The `save_model` methods in `AbadIA/NGDQN.py` and `AbadIA/VDQN.py` could benefit from more explicit model versioning. \n    * Include version numbers or timestamps in the model file names to keep track of different model iterations.\n"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "    * Use a version control system (like Git) to manage the code and model files.\n\n* **Error handling during training:**\n    * Implement mechanisms to handle potential errors during training, such as divergence of loss, out-of-memory errors, or network connectivity issues.\n    * Log errors, potentially"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " stop training gracefully, and save the current state for later analysis or resumption.\n\n* **Hyperparameter tuning:**\n    * Use a structured approach for tuning hyperparameters (like grid search or Bayesian optimization) to find the best settings for your model.\n    * Log hyperparameters used for each training run for reproducibility."
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n**3. Logging and Monitoring**\n\n* **Structured logging:** \n    * Standardize logging across the codebase, using a consistent format and logging levels (e.g., INFO, WARNING, ERROR).\n    * Log key events, such as actions taken, rewards received, model training progress, and"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " errors encountered.\n    * Use a structured logging format (e.g., JSON) to facilitate parsing and analysis of logs.\n\n* **Performance monitoring:**\n    * Implement metrics to track the performance of the agent during training and testing, such as average reward, episode length, success rate, etc.\n    "
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "* Visualize these metrics over time to monitor training progress and identify potential issues.\n    * Consider using a monitoring tool like TensorBoard to visualize training metrics and model graphs.\n\n**4. Code Organization and Testing**\n\n* **Modular design:**\n    * Break down the code into smaller, more manageable modules with"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " clearly defined responsibilities. \n    * Improve code readability, maintainability, and testability.\n\n* **Unit tests:**\n    * Write unit tests to cover the core functions and logic of the codebase, especially for critical components like state vectorization, action validation, and model training/saving. \n"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "    * Ensure that the code functions as expected and helps detect regressions during development.\n\n**5. Cloud Integration (if applicable)**\n\n* **Error handling for cloud operations:**\n    * The code uses Google Cloud Storage. \n    * Ensure robust error handling for cloud operations like downloading/uploading files, handling"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " potential network issues, and authentication failures.\n    * Implement retries and exponential backoff for transient errors.\n\n* **Resource management:**\n    * Implement efficient resource management for cloud resources. \n    * Release resources promptly when no longer needed to avoid unnecessary costs.\n\n**Specific Recommendations based on R9y."
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "dev**\n\n* **Defensive programming:** Apply defensive programming principles throughout the codebase, checking for potential error conditions and handling them gracefully.\n* **Use assertions:** Use assertions liberally to verify assumptions about the code and data.\n* **Limit dependencies:** Minimize the number of external libraries and dependencies to reduce the potential attack"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " surface and complexity.\n\n**Note:** These suggestions are general guidelines. Prioritizing and implementing them should be based on a thorough understanding of the application's specific requirements and the criticality of its reliability.\n"
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  How can I make this application more reliable? Consider best practices from https://www.r9y.dev/\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf1jNDpJj8u0"
      },
      "source": [
        "### 8. Making the app more secure\n",
        "\n",
        "Recommend best practices to make the application more secure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Hy_mCyFVLlXU",
        "outputId": "197c882d-fe42-43f2-a380-94c4fad8b3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " codebase represents a reinforcement learning project for the game \"The Abbey of Crime\""
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " (AbadIA), leveraging OpenAI Gym and Google Cloud Platform (GCP"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "). While the code focuses on the agent's learning and interaction with the game, security considerations seem to be largely absent. Here's a breakdown of potential"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " vulnerabilities and how to address them:\n\n**1. Communication with the Game Engine**\n\n* **Unencrypted Communication:** The code uses HTTP requests to communicate with"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " the game engine (VigasocoSDL-AI). This is insecure as it exposes communication to eavesdropping and potential manipulation.\n    * **Solution:** Switch to HTTPS for secure, encrypted communication between the agent and the game engine. You"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "'ll need to configure VigasocoSDL-AI to support HTTPS.\n\n* **No Authentication/Authorization:** The code doesn't appear to use any authentication or authorization mechanisms when interacting with the game engine. This means any client could"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " potentially send commands to the game engine.\n    * **Solution:** Implement a robust authentication system, such as API keys, tokens, or OAuth, to verify the identity of the agent. Additionally, consider authorization to restrict what commands the agent can execute.\n\n* **Input Validation:** There's no evident input validation"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " for commands received from the agent. Malformed or malicious commands could cause unexpected behavior or even crashes in the game engine.\n    * **Solution:** Implement rigorous input validation in VigasocoSDL-AI. Check the format, type, and allowed values of all commands received from the agent. Sanitize any user-"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "provided input before processing.\n\n**2. Cloud Storage (GCP)**\n\n* **Bucket Permissions:** The code interacts with a GCP storage bucket (abadia-data). Excessive permissions on the bucket could allow unauthorized access or modification of training data, models, or checkpoints.\n    * **Solution:** Follow the principle"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " of least privilege. Grant only the necessary permissions (read, write, delete) to the specific service accounts or users that require them. Regularly audit bucket permissions.\n\n* **Sensitive Data Exposure:** Checkpoints and game data may contain information that should not be publicly accessible.\n    * **Solution:** Encrypt sensitive data before"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " uploading it to the cloud. Use GCP's encryption features (e.g., Cloud KMS) for secure key management.\n\n\n**3. General Security Practices**\n\n* **Dependency Management:**  The `requirements.txt` file lists dependencies. Regularly update these dependencies to patch known vulnerabilities.\n    * **"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Solution:** Use tools like `pip-audit` or `safety` to scan for vulnerable dependencies. Keep your environment up to date using `pip install -r requirements.txt --upgrade`. \n\n* **Logging:** The code uses basic logging, but it's important to consider what data is being logged and whether"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " any of it is sensitive.\n    * **Solution:** Avoid logging sensitive information like passwords or API keys. Configure logging levels appropriately (INFO, DEBUG, etc.) and be mindful of the storage location and retention policies for logs.\n\n**4. Kubernetes Security**\n\n* **Container Images:** The Kubernetes YAML files (`"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "k8s/` directory) specify container images. These images could have vulnerabilities if not properly secured.\n    * **Solution:** Use trusted base images. Scan images for vulnerabilities using tools like Clair, Anchore, or Trivy. Implement image signing to verify the integrity of images.\n\n* **Pod Security:**"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Kubernetes pods should be configured with appropriate security contexts.\n    * **Solution:** Define resource limits to prevent resource exhaustion. Use security contexts to control privileges, network access, and filesystem access within the pod. \n\n**Implementation Notes:**\n\n* Secure coding practices should be integrated throughout the codebase, not just in isolated"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " modules.\n* Regular security testing and vulnerability scanning are essential to identify and mitigate risks.\n* Consider using security tools and libraries designed for Python and GCP.\n\nBy addressing these vulnerabilities, you can significantly enhance the security of this reinforcement learning application and protect its data, models, and infrastructure. \n"
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  How can you secure the application?\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFfwMOb6kYfw"
      },
      "source": [
        "### 9. Learning the codebase\n",
        "\n",
        "Create a quiz about the concepts used in the codebase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "l7jQIUwsNRH4",
        "outputId": "74cd113f-bff3-40f9-c3c7-dbb71d7c8d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "python\nimport json\nimport random\n\n# Questions and answers are stored as a"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " list of dictionaries\nquiz_data = [\n    {\n        \"question"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\": \"What type of learning algorithm is primarily used in 'agentv2_qlearning.py' and 'agentv3_qlearning.py'"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "?\",\n        \"options\": [\"a) Deep Q-learning\", \"b) Q-learning\", \"c) Monte Carlo Tree Search\", \"d)"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Random Agent\"],\n        \"answer\": \"b\"\n    },\n    {\n        \"question\": \"In 'agentv4_dqn.py', what data structure is used to store the agent's experiences for training"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "?\",\n        \"options\": [\"a) List\", \"b) Deque\", \"c) Dictionary\", \"d) Set\"],\n        \"answer\": \"b\"\n    },\n    {\n        \"question\": \"What"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " is the purpose of the 'gamma' parameter in the DQN and NDQN classes?\",\n        \"options\": [\"a) Learning rate\", \"b) Discount factor\", \"c) Exploration rate\", \"d) Number of episodes\"],\n        \"answer\": \"b\"\n    },\n    {\n        "
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\"question\": \"Which file is responsible for extracting vectors from actions and storing them in a directory?\",\n        \"options\": [\"a) 'agentv6_ngdqn.py'\", \"b) 'pre_training_VDQN.py'\", \"c) 'extract_vectors_from_actions."
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "py'\", \"d) 'training_NGDQN.py'\"],\n        \"answer\": \"c\"\n    },\n    {\n        \"question\": \"What is the purpose of the 'checkValidMovs' function in 'agentv5_dqn.py' and 'agentv6"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "_ngdqn.py'?\",\n        \"options\": [\"a)  To determine valid movements based on the game's state\", \"b) To check if the game is over\", \n                   \"c) To save the game's state\", \"d) To calculate the reward for the agent"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\"],\n        \"answer\": \"a\"\n    },\n    {\n        \"question\": \"What Keras optimizer is used to compile the models in the DQN, NDQN, and VDQN classes?\",\n        \"options\": [\"a) SGD\", \"b) RMSprop\", \"c) Ad"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "agrad\", \"d) Adam\"],\n        \"answer\": \"d\"\n    },\n    {\n        \"question\": \"What is the purpose of the 'visited_snap_save' and 'visited_snap_load' functions?\",\n        \"options\": [\"a) To save and load the game"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "'s checkpoints\", \"b) To save and load the Q-table\", \n                   \"c) To save and load a map of visited locations in the game\", \"d) To store and retrieve the game's history\"],\n        \"answer\": \"c\"\n    },\n    {\n        "
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\"question\": \"What is the purpose of the 'target_model' in the DQN, NDQN, and VDQN classes?\",\n        \"options\": [\"a) To store the best performing model during training\", \n                   \"b) To provide a stable target for Q-value updates\",\n"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "                   \"c)  To predict the agent's next action\", \n                   \"d) To evaluate the agent's performance\"],\n        \"answer\": \"b\"\n    },\n    {\n        \"question\": \"What Google Cloud service is used for storing and retrieving models and game data?\",\n"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        \"options\": [\"a) Google Drive\", \"b) Google Cloud Storage\", \"c) Google Colab\", \"d) Google Cloud SQL\"],\n        \"answer\": \"b\"\n    },\n    {\n        \"question\": \"Which file defines the OpenAI Gym environment for the 'Abbey of"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Crime' game?\",\n        \"options\": [\"a) 'training_models.py'\", \"b) 'gym_abadia/gym_abadia/envs/abadia_env.py'\",\n                   \"c) 'agentv1.py'\", \"d)  'AbadIA/VD"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "QN.py'\"],\n        \"answer\": \"b\"\n    }\n]\n\n# Function to present a question and get the user's answer\ndef ask_question(question_data):\n    print(question_data[\"question\"])\n    for option in question_data[\"options\"]:\n"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        print(option)\n    while True:\n        user_answer = input(\"Enter your answer (a, b, c, or d): \").lower()\n        if user_answer in [\"a\", \"b\", \"c\", \"d\"]:\n            break\n        print(\"Invalid input. Please"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " enter a, b, c, or d.\")\n    return user_answer\n\n# Main quiz loop\ndef run_quiz(quiz_data):\n    score = 0\n    random.shuffle(quiz_data)  # Shuffle the questions\n    for question_data in quiz_data:\n"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        user_answer = ask_question(question_data)\n        if user_answer == question_data[\"answer\"]:\n            print(\"Correct!\\n\")\n            score += 1\n        else:\n            print(f\"Incorrect. The answer was {question_data['options'][ord("
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "question_data['answer']) - ord('a')]}.\\n\")\n    print(f\"You got {score} out of {len(quiz_data)} questions right.\")\n\n# Run the quiz\nif __name__ == \"__main__\":\n    run_quiz(quiz_data)\n``` "
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n"
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  Create a quiz about the concepts used in my codebase to help me solidify my understanding.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjo1UrZwGLan"
      },
      "source": [
        "### 10. Creating a quickstart tutorial\n",
        "\n",
        "Create an end-to-end quickstart tutorial for a specific component.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FRwmRyDDFRMB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68ee99bb-05a1-4d87-f290-342e38bd8228"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "python\nimport gym\nimport gym_abadia\nimport numpy as np\n"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "import os\nimport argparse\nimport random\nimport json\nimport AbadIA."
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "NGDQN\n\nfrom google.cloud import sql_v1beta4\nfrom google.cloud import storage\n\n# Initialize Google Cloud Storage client\nstorage_"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "client = storage.Client()\n\ndef init_env(env):\n    \"\"\"\n    Initializes the environment with arguments passed from the command line.\n"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "    \"\"\"\n    argparser = argparse.ArgumentParser()\n    argparser.add_argument('-s', '--server', help='AlloyDB instance connection name', required=True)\n    argparser.add_argument('-d',"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " '--database', help='AlloyDB database name', required=True)\n    argparser.add_argument('-u', '--user', help='AlloyDB username', required=True)\n    argparser.add_argument('-p"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "', '--password', help='AlloyDB password', required=True)\n    argparser.add_argument('-b', '--bucket', help='Google Cloud Storage bucket name', required=True)\n    argparser.add_argument('-c', '--checkpoint', help='Checkpoint file')\n    argparser."
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "add_argument('-m', '--model', help='Model file')\n    argparser.add_argument('-e', '--episodes', help='Number of episodes', type=int, default=1)\n    argparser.add_argument('-n', '--steps', help='Total steps per episode', type"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "=int, default=5000)\n    argparser.add_argument('-l', '--learning', help='Learning mode (True/False)', default='True')\n    argparser.add_argument('-v', '--verbose', help='Verbose output', type=int, default=1)"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n    args = argparser.parse_args()\n\n    # Set AlloyDB connection parameters\n    env.alloydb_connection_name = args.server\n    env.alloydb_database = args.database\n    env.alloydb_user = args.user\n    env.alloydb_"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "password = args.password\n\n    # Configure the CartService to use AlloyDB.\n    env.cart_service = CartService(env.alloydb_connection_name, env.alloydb_database, env.alloydb_user, env.alloydb_password)\n\n    # Set Google Cloud"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Storage parameters\n    env.gs_bucket_name = args.bucket\n    env.gs_bucket = storage_client.bucket(env.gs_bucket_name)\n\n    # Other environment parameters\n    if args.checkpoint:\n        env.checkpoint_name = args.checkpoint\n    if"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " args.model:\n        env.model_name = args.model\n    env.num_episodes = args.episodes\n    env.num_steps = args.steps\n    env.playing = args.learning == 'False'  \n    env.verbose = args.verbose\n\n\ndef main_"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "loop():\n    \"\"\"\n    Main loop for running the game and the agent.\n    \"\"\"\n    logging.info(\"Loading visited snap file\")\n    env.visited_snap_load()\n\n    r_list = []\n    \n    # NGDQN parameters\n    gamma = 0."
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "9\n    epsilon = .95\n\n    ngdqn_agent = AbadIA.NGDQN.NGDQN(env=env, initModelName=\"models/last_model_v6.model\")\n    \n    for i_episode in range(env.num_episodes):\n"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        logging.info(f'Running {i_episode} episode')\n        state = env.reset()\n        if env.checkpoint_name:\n            state = env.load_game_checkpoint(env.checkpoint_name)\n\n        r_all = 0\n        done = False\n\n"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "        for t in range(env.num_steps):\n            # Get Guillermo's and Adso's positions\n            x, y, ori = env.personaje_by_name('Guillermo')\n            adso_x, adso_y, _ = env.personaje_by"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "_name('Adso')\n\n            # Choose an action\n            action = ngdqn_agent.act(state)\n\n            # Execute the action in the environment\n            env.prev_vector = env.vector\n            while True:\n                new_state, reward, done, info = env"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".step(action)\n                env.save_action(state, action, reward, new_state)\n                if env.esta_guillermo:\n                    break\n\n            # Store experience in memory\n            ngdqn_agent.remember(env.prev_vector, action, reward, env"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ".vector, done)\n\n            # End episode if done\n            if done:\n                logging.info(f'Episode finished after {t+1} steps')\n                env.save_game()\n                if env.ha_fracasado:\n                    logging.info(f'Episode finished"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " with a FAIL')\n                    env.reset_fin_partida()\n                    break\n\n            # Update visited map \n            new_x, new_y, _ = env.personaje_by_name('Guillermo')\n            if x != new_x or y != new_y:\n                "
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "env.Visited[new_x, new_y] += 1\n            if x == new_x and y == new_y:\n                if ori == 0:\n                    env.Visited[x + 1, y] += -0.01\n                if ori == 1"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ":\n                    env.Visited[x, y - 1] += -0.01\n                if ori == 2:\n                    env.Visited[x - 1, y] += -0.01\n                if ori == 3:\n                    env.Visited[x, y"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " + 1] += -0.01\n\n            # Train the agent\n            if not env.playing:\n                ngdqn_agent.replay()\n                ngdqn_agent.target_train()\n\n            # Logging and rendering\n            env.pinta_rejilla(40"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", 20)\n            logging.info(\n                f\"E{i_episode}:{t} {action}-{env.actions_list[action]}: \"\n                f\"X:{x} Y:{y},{ori},{env.num_pantalla}->{new_x},{new_y"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "} \"\n                f\"O:{env.obsequium} %{env.porcentaje} \"\n                f\"reward:{np.round(reward, 8)} tr:{np.round(r_all, 8)} \"\n                f\"V:{np.round(env.predictions,"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " 4)}\"\n            )\n\n            # Update state and cumulative reward\n            r_all += reward\n            state = new_state\n            if done:\n                logging.info(\"DONE is True, exit and don't save the game\")\n                break\n\n        # Save checkpoint and game data"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n        if r_all > 0:\n            env.save_game_checkpoint()\n        env.save_game()\n\n        # Save the model\n        if env.model_name:\n            ngdqn_agent.save_model(env.model_name)\n            if"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " env.gs_bucket_name:\n                logging.info(\"Uploading model to GCP\")\n                env.upload_blob(env.model_name, env.model_name)\n\n        # Store total reward for the episode\n        r_list.append(r_all)\n\n        # Logging"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n        if t >= env.num_steps:\n            logging.info(f\"Failed to complete in trial {env.num_episodes}\")\n\n        # Save visited map occasionally\n        if np.random.randint(10) <= 1:\n            env.visited_snap_save()"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n    logging.info(f\"Score over time: {sum(r_list) / env.num_episodes}\")\n\n\nclass CartService:\n    \"\"\"\n    Example service for interacting with a shopping cart, \n    configured to use AlloyDB for persistence. \n    \"\"\"\n\n    def __"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "init__(self, connection_name, database, user, password):\n        self.connection_name = connection_name\n        self.database = database\n        self.user = user\n        self.password = password\n        self.db_client = self._create_db_client()\n\n    "
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "def _create_db_client(self):\n        # Create a client for connecting to AlloyDB\n        db_client = sql_v1beta4.Client()\n        return db_client\n\n    # Add methods for interacting with the cart, like adding/removing items, etc.\n    #"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " These methods would use the db_client to execute queries against AlloyDB. \n    # Example:\n    def get_item(self, item_id):\n        with self.db_client.connect(self.connection_name, self.user, self.password, self.database) as"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " conn:\n            with conn.cursor() as cursor:\n                cursor.execute(\"SELECT * FROM items WHERE item_id = %s\", (item_id,))\n                result = cursor.fetchone()\n                return result\n\nif __name__ == '__main__':\n    env = gym.make('"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Abadia-v2')\n    init_env(env)\n    main_loop()\n```\n\n**Explanation:**\n\n1. **AlloyDB Configuration:**\n   - We use command line arguments to pass AlloyDB connection details: instance name, database, username, and password.\n   - The `"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "CartService` class is an example service in your Online Boutique application that interacts with AlloyDB. You'd replace this with your actual service class.\n   - The `CartService` initializes a connection to AlloyDB using the provided credentials.\n\n2. **CartService Integration:**\n   - The `init_"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "env` function sets up a `CartService` instance (`env.cart_service`) using the AlloyDB connection parameters. \n   - Now, any part of your application that needs to access cart data can use `env.cart_service` and its methods, which communicate with AlloyDB.\n\n3."
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " **Key AlloyDB Capabilities (in the context of Online Boutique):**\n   - **High Performance:** AlloyDB excels in transactional workloads like managing shopping carts. Its in-memory capabilities and optimized query processing ensure fast responses for cart operations (adding items, viewing cart contents, checkout).\n   - **Scalability:**"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " AlloyDB can handle a large number of concurrent users interacting with their shopping carts, especially important during peak shopping seasons.\n   - **Data Consistency:** AlloyDB ensures that cart data is always consistent and accurate, preventing errors like items disappearing from carts or incorrect order totals.\n\n**Quickstart Steps:**\n\n1. **"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Set up an AlloyDB instance and database:** Follow the instructions in the Google Cloud documentation to create an AlloyDB instance and a database for your Online Boutique application ([https://cloud.google.com/alloydb/docs/](https://cloud.google.com/alloydb/docs/)).\n\n2. **"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Update the Online Boutique CartService:** Modify your existing `CartService` class (or create a new one) to use AlloyDB for persistence. Implement the methods you need for cart operations using the `google.cloud.sql_v1beta4` library to connect to AlloyDB and execute SQL queries.\n\n3"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ". **Modify the code:** Replace the placeholder `CartService` class and its methods in the provided example code with your actual implementation.\n\n4. **Install the necessary libraries:**\n   ```bash\n   pip install google-cloud-sql google-cloud-storage\n   ```\n\n5. **Run the example"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ":**\n   ```bash\n   python3 your_script.py \\\n     --server your-alloydb-connection-name \\\n     --database your-alloydb-database \\\n     --user your-alloydb-user \\\n     --password your-alloydb-password \\\n     --"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "bucket your-gcs-bucket-name \n   ```\n\n**Important Notes:**\n\n- This is a simplified example. You'll need to adapt it to your specific Online Boutique implementation.\n- Remember to follow security best practices for managing your AlloyDB credentials (using secrets management).\n- Explore other features of"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " AlloyDB, like its integration with Cloud Spanner, for more advanced use cases. \n"
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "  Please write an end-to-end quickstart tutorial that introduces AlloyDB,\n",
        "  shows how to configure it with the CartService,\n",
        "  and highlights key capabilities of AlloyDB in context of the Online Boutique application.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAJ-kBCZnlH_"
      },
      "source": [
        "### 11. Creating a Git Changelog Generator\n",
        "\n",
        "Understanding changes made between Git commits and highlighting the most important aspects of the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jdeWO8crnlH_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "2aa6cc54-b47b-4fb4-aac5-36356d5028fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "GitCommandError",
          "evalue": "Cmd('git') failed due to: exit code(128)\n  cmdline: git rev-list main --\n  stderr: 'fatal: bad revision 'main'\n'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGitCommandError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-32660c4189ca>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRepo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbranch_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m commit_ids = [\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcommit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexsha\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcommit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_commits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ]  # A list of commit IDs (SHA-1 hashes) in reverse chronological order (newest first)\n",
            "\u001b[0;32m<ipython-input-25-32660c4189ca>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRepo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbranch_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m commit_ids = [\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcommit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexsha\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcommit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_commits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ]  # A list of commit IDs (SHA-1 hashes) in reverse chronological order (newest first)\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/git/objects/commit.py\u001b[0m in \u001b[0;36m_iter_from_process_or_stream\u001b[0;34m(cls, repo, proc_or_stream)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_or_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wait\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mproc_or_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc_or_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             \u001b[0mfinalize_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_or_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/git/util.py\u001b[0m in \u001b[0;36mfinalize_process\u001b[0;34m(proc, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     accordingly.\"\"\"\n\u001b[1;32m    503\u001b[0m     \u001b[0;31m# TODO: No close proc-streams??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/git/cmd.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, stderr)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0merrstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_all_from_possibly_closed_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_stderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AutoInterrupt wait stderr: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mGitCommandError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_password_if_present\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGitCommandError\u001b[0m: Cmd('git') failed due to: exit code(128)\n  cmdline: git rev-list main --\n  stderr: 'fatal: bad revision 'main'\n'"
          ]
        }
      ],
      "source": [
        "### Fetches commit IDs from a local Git repository on a specified branch.\n",
        "\n",
        "repo = git.Repo(repo_dir)\n",
        "branch_name = \"main\"\n",
        "commit_ids = [\n",
        "    commit.hexsha for commit in repo.iter_commits(branch_name)\n",
        "]  # A list of commit IDs (SHA-1 hashes) in reverse chronological order (newest first)\n",
        "\n",
        "if len(commit_ids) >= 2:\n",
        "    diff_text = repo.git.diff(commit_ids[0], commit_ids[1])\n",
        "\n",
        "    question = \"\"\"\n",
        "      Given the above git diff output, Summarize the important changes made.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = diff_text + question + code_text\n",
        "    contents = [prompt]\n",
        "\n",
        "    responses = model.generate_content(contents, stream=True)\n",
        "    for response in responses:\n",
        "        IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kUeIBfGyoX7"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, you've learned how to use the Gemini 1.5 Pro to analyze a codebase and prompt the model to:\n",
        "\n",
        "- Summarize codebases effortlessly.\n",
        "- Generate clear developer getting-started documentation.\n",
        "- Uncover critical bugs and provide fixes.\n",
        "- Implement new features and improve reliability and security.\n",
        "- Understanding changes made between Git commits"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-12.m110",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}